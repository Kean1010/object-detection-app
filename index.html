<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Object Detection App</title>
<style>
  body {
    font-family: Arial, sans-serif;
    text-align: center;
    margin: 0;
    padding: 20px;
    background-color: #f4f4f9;
  }
  h1 {
    color: #333;
  }
  #camera {
    width: 100%;
    max-width: 600px;
    margin-bottom: 20px;
  }
  #result {
    font-size: 24px;
    font-weight: bold;
    color: #28a745;
  }
  canvas {
    position: absolute;
    top: 0;
    left: 0;
    width: 100%;
    max-width: 600px;
    pointer-events: none;
  }
</style>
</head>
<body>
<h1>Object Detection App</h1>
<p>Point your camera at objects to detect them.</p>
<video id="camera" autoplay playsinline></video>
<canvas id="canvas"></canvas>
<div id="result">Detecting...</div>

<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
<script>
  let model;
  let video;
  let canvas;
  let ctx;

  async function setupCamera() {
    video = document.getElementById('camera');
    const stream = await navigator.mediaDevices.getUserMedia({ video: true });
    video.srcObject = stream;
    return new Promise((resolve) => {
      video.onloadedmetadata = () => {
        resolve(video);
      };
    });
  }

  async function loadModel() {
    console.log('Loading COCO-SSD model...');
    model = await cocoSsd.load();
    console.log('Model loaded successfully.');
  }

  function drawBoundingBoxes(predictions) {
    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;
    ctx.clearRect(0, 0, canvas.width, canvas.height);

    predictions.forEach(prediction => {
      const [x, y, width, height] = prediction.bbox;
      // Draw bounding box
      ctx.strokeStyle = '#28a745';
      ctx.lineWidth = 2;
      ctx.strokeRect(x, y, width, height);

      // Draw label background
      ctx.fillStyle = '#28a745';
      const textHeight = 16;
      ctx.fillRect(x, y, ctx.measureText(prediction.class).width + 10, textHeight);

      // Draw label text
      ctx.fillStyle = '#fff';
      ctx.font = `${textHeight}px Arial`;
      ctx.fillText(prediction.class, x + 5, y + 14);
    });
  }

  function speak(text) {
    const utterance = new SpeechSynthesisUtterance(text);
    utterance.lang = 'en-US'; // Set language (optional)
    utterance.rate = 0.9; // Slower speech rate
    window.speechSynthesis.speak(utterance);
  }

  async function detectObjects() {
    if (model && video.readyState === video.HAVE_ENOUGH_DATA) {
      const predictions = await model.detect(video);
      if (predictions.length > 0) {
        const topPrediction = predictions[0];
        const resultText = `I see: ${topPrediction.class} (${Math.round(topPrediction.score * 100)}%)`;
        document.getElementById('result').textContent = resultText;
        speak(resultText);

        // Draw bounding boxes on the canvas
        drawBoundingBoxes(predictions);
      } else {
        document.getElementById('result').textContent = 'No objects detected.';
      }
    }
    // Schedule the next detection after 1 second
    setTimeout(detectObjects, 1000);
  }

  async function main() {
    try {
      canvas = document.getElementById('canvas');
      ctx = canvas.getContext('2d');

      await loadModel();
      await setupCamera();
      detectObjects(); // Start the detection loop
    } catch (error) {
      console.error('Error:', error);
      document.getElementById('result').textContent = 'Error initializing app.';
    }
  }

  main();
</script>
</body>
</html>
