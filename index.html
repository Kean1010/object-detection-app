<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Object Detection App</title>
<style>
  body {
    font-family: Arial, sans-serif;
    text-align: center;
    margin: 0;
    padding: 20px;
    background-color: #f4f4f9;
  }
  h1 {
    color: #333;
  }
  #camera {
    width: 100%;
    max-width: 600px;
    margin-bottom: 20px;
  }
  #result {
    font-size: 24px;
    font-weight: bold;
    color: #28a745;
  }
  canvas {
    position: absolute;
    top: 0;
    left: 0;
    width: 100%;
    max-width: 600px;
    pointer-events: none;
  }
  #switchCameraButton {
    margin-top: 10px;
    padding: 10px 20px;
    font-size: 16px;
    background-color: #28a745;
    color: white;
    border: none;
    border-radius: 5px;
    cursor: pointer;
  }
  #switchCameraButton:hover {
    background-color: #218838;
  }
</style>
</head>
<body>
<h1>Object Detection App</h1>
<p>Point your camera at objects to detect them.</p>
<video id="camera" autoplay playsinline></video>
<canvas id="canvas"></canvas>
<div id="result">Detecting...</div>
<button id="switchCameraButton">Switch Camera</button>

<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
<script>
  let model;
  let video;
  let canvas;
  let ctx;
  let currentFacingMode = 'environment'; // Start with the rear camera
  let lastSpokenText = ''; // Track the last spoken text to avoid repetition

  async function setupCamera() {
    const constraints = {
      video: { facingMode: currentFacingMode }
    };

    try {
      const stream = await navigator.mediaDevices.getUserMedia(constraints);
      video.srcObject = stream;
      return new Promise((resolve) => {
        video.onloadedmetadata = () => {
          resolve(video);
        };
      });
    } catch (error) {
      console.error('Error accessing camera:', error);
      alert('Unable to access camera. Please check permissions.');
    }
  }

  async function loadModel() {
    console.log('Loading COCO-SSD model...');
    model = await cocoSsd.load();
    console.log('Model loaded successfully.');
  }

  function drawBoundingBoxes(predictions) {
    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;
    ctx.clearRect(0, 0, canvas.width, canvas.height);

    predictions.forEach(prediction => {
      const [x, y, width, height] = prediction.bbox;
      // Draw bounding box
      ctx.strokeStyle = '#28a745';
      ctx.lineWidth = 2;
      ctx.strokeRect(x, y, width, height);

      // Draw label background
      ctx.fillStyle = '#28a745';
      const textHeight = 16;
      ctx.fillRect(x, y, ctx.measureText(prediction.class).width + 10, textHeight);

      // Draw label text
      ctx.fillStyle = '#fff';
      ctx.font = `${textHeight}px Arial`;
      ctx.fillText(prediction.class, x + 5, y + 14);
    });
  }

  function speak(text) {
    // Cancel any ongoing or queued speech
    window.speechSynthesis.cancel();

    // Avoid repeating the same text
    if (text === lastSpokenText) return;

    // Update the last spoken text
    lastSpokenText = text;

    // Create and speak the new utterance
    const utterance = new SpeechSynthesisUtterance(text);
    utterance.lang = 'en-US'; // Set language (optional)
    utterance.rate = 0.9; // Slower speech rate
    window.speechSynthesis.speak(utterance);
  }

  async function detectObjects() {
    if (model && video.readyState === video.HAVE_ENOUGH_DATA) {
      const predictions = await model.detect(video);
      if (predictions.length > 0) {
        const topPrediction = predictions[0];
        const resultText = `I see: ${topPrediction.class} (${Math.round(topPrediction.score * 100)}%)`;
        document.getElementById('result').textContent = resultText;

        // Speak the latest detection result
        speak(resultText);

        // Draw bounding boxes on the canvas
        drawBoundingBoxes(predictions);
      } else {
        document.getElementById('result').textContent = 'No objects detected.';
      }
    }
    // Schedule the next detection after 1 second
    setTimeout(detectObjects, 1000);
  }

  async function toggleCamera() {
    // Toggle between 'user' (front camera) and 'environment' (rear camera)
    currentFacingMode = currentFacingMode === 'environment' ? 'user' : 'environment';

    // Stop the current video stream
    const stream = video.srcObject;
    if (stream) {
      const tracks = stream.getTracks();
      tracks.forEach(track => track.stop());
    }

    // Reinitialize the camera with the new facing mode
    await setupCamera();
  }

  async function main() {
    try {
      video = document.getElementById('camera');
      canvas = document.getElementById('canvas');
      ctx = canvas.getContext('2d');

      await loadModel();
      await setupCamera();
      detectObjects(); // Start the detection loop

      // Add event listener for the "Switch Camera" button
      document.getElementById('switchCameraButton').addEventListener('click', toggleCamera);
    } catch (error) {
      console.error('Error:', error);
      document.getElementById('result').textContent = 'Error initializing app.';
      alert(`Error: ${error.message}`);
    }
  }

  main();
</script>
</body>
</html>
